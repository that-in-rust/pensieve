//! Content Extractor for Task List Generation
//!
//! This module provides the ContentExtractor struct that handles extracting database content
//! and generating A/B/C files with contextual information for systematic analysis.

use crate::error::{TaskError, TaskResult};
use sqlx::{PgPool, Row};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tracing::{debug, info};

/// Content extractor for generating A/B/C analysis files
#[derive(Clone, Debug)]
pub struct ContentExtractor {
    db_pool: Arc<PgPool>,
    output_dir: PathBuf,
}

/// Triple of content files for analysis (A/B/C pattern)
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct ContentTriple {
    /// Raw content file (A)
    pub content_a: PathBuf,
    /// L1 context file (B) - immediate file context
    pub content_b: PathBuf,
    /// L2 context file (C) - architectural context
    pub content_c: PathBuf,
    /// Row number from database
    pub row_number: usize,
    /// Table name this content came from
    pub table_name: String,
}

/// Metadata extracted from a database row for context generation
#[derive(Debug, Clone)]
pub struct RowMetadata {
    pub file_id: Option<i64>,
    pub filepath: Option<String>,
    pub filename: Option<String>,
    pub extension: Option<String>,
    pub file_size_bytes: Option<i64>,
    pub line_count: Option<i32>,
    pub word_count: Option<i32>,
    pub content_text: Option<String>,
    pub file_type: Option<String>,
    pub relative_path: Option<String>,
    pub absolute_path: Option<String>,
}

impl ContentExtractor {
    /// Create a new ContentExtractor with database pool and output directory
    ///
    /// # Arguments
    /// * `db_pool` - PostgreSQL connection pool
    /// * `output_dir` - Directory where A/B/C files will be created
    ///
    /// # Returns
    /// * `Self` - New ContentExtractor instance
    pub fn new(db_pool: Arc<PgPool>, output_dir: PathBuf) -> Self {
        Self { db_pool, output_dir }
    }

    /// Extract all rows from a table and create A/B/C content files
    ///
    /// # Arguments
    /// * `table_name` - Name of the table to extract from
    ///
    /// # Returns
    /// * `TaskResult<Vec<ContentTriple>>` - List of created content file triples
    ///
    /// # Examples
    /// ```rust
    /// let extractor = ContentExtractor::new(pool, PathBuf::from(".raw_data_202509"));
    /// let triples = extractor.extract_all_rows("INGEST_20250928101039").await?;
    /// println!("Created {} content triples", triples.len());
    /// ```
    pub async fn extract_all_rows(&self, table_name: &str) -> TaskResult<Vec<ContentTriple>> {
        debug!("Extracting all rows from table: {}", table_name);

        // Validate table name
        self.validate_table_name(table_name)?;

        // Query all rows from the table
        let query = format!(
            "SELECT file_id, filepath, filename, extension, file_size_bytes, 
                    line_count, word_count, content_text, file_type, 
                    relative_path, absolute_path 
             FROM \"{}\" 
             ORDER BY file_id",
            table_name
        );

        debug!("Executing query: {}", query);

        let rows = sqlx::query(&query)
            .fetch_all(&*self.db_pool)
            .await
            .map_err(|e| TaskError::QueryResultProcessingFailed {
                cause: format!("Failed to fetch rows from table '{}': {}", table_name, e),
            })?;

        info!("Retrieved {} rows from table '{}'", rows.len(), table_name);

        // Create content files for each row
        let mut content_triples = Vec::new();
        for (row_num, row) in rows.iter().enumerate() {
            let row_number = row_num + 1; // 1-based numbering

            // Extract metadata from the row
            let metadata = self.extract_row_metadata(&row)?;

            // Create content files for this row
            let content_triple = self.create_content_files(&metadata, row_number, table_name).await?;
            content_triples.push(content_triple);
        }

        info!("Created {} content file triples for table '{}'", content_triples.len(), table_name);
        Ok(content_triples)
    }

    /// Create A/B/C content files for a single database row
    ///
    /// # Arguments
    /// * `metadata` - Row metadata extracted from database
    /// * `row_number` - Row number (1-based)
    /// * `table_name` - Name of the source table
    ///
    /// # Returns
    /// * `TaskResult<ContentTriple>` - Created content file triple
    pub async fn create_content_files(
        &self,
        metadata: &RowMetadata,
        row_number: usize,
        table_name: &str,
    ) -> TaskResult<ContentTriple> {
        debug!("Creating content files for row {} from table '{}'", row_number, table_name);

        // Ensure output directory exists
        tokio::fs::create_dir_all(&self.output_dir).await.map_err(|e| {
            TaskError::TaskFileCreationFailed {
                path: self.output_dir.display().to_string(),
                cause: format!("Failed to create output directory: {}", e),
            }
        })?;

        // Generate file paths
        let base_name = format!("{}_{}_Content", table_name, row_number);
        let content_a = self.output_dir.join(format!("{}.txt", base_name));
        let content_b = self.output_dir.join(format!("{}_L1.txt", base_name));
        let content_c = self.output_dir.join(format!("{}_L2.txt", base_name));

        // Get raw content
        let raw_content = metadata.content_text.as_deref().unwrap_or("");

        // Generate L1 context (immediate file context)
        let l1_context = self.generate_l1_context(raw_content, metadata);

        // Generate L2 context (architectural context)
        let l2_context = self.generate_l2_context(raw_content, metadata);

        // Write content files
        self.write_content_file(&content_a, raw_content).await?;
        self.write_content_file(&content_b, &l1_context).await?;
        self.write_content_file(&content_c, &l2_context).await?;

        debug!("Created content files: A={}, B={}, C={}", 
               content_a.display(), content_b.display(), content_c.display());

        Ok(ContentTriple {
            content_a,
            content_b,
            content_c,
            row_number,
            table_name: table_name.to_string(),
        })
    }

    /// Generate L1 context (immediate file context)
    ///
    /// L1 context includes:
    /// - Same directory files
    /// - Import/include relationships
    /// - Module-level dependencies
    ///
    /// # Arguments
    /// * `content` - Raw file content
    /// * `metadata` - File metadata from database
    ///
    /// # Returns
    /// * `String` - Generated L1 context
    pub fn generate_l1_context(&self, content: &str, metadata: &RowMetadata) -> String {
        debug!("Generating L1 context for file: {:?}", metadata.filepath);

        let mut context = String::new();

        // Add file metadata header
        context.push_str("# L1 Context: Immediate File Context\n\n");
        context.push_str("## File Information\n\n");

        if let Some(filepath) = &metadata.filepath {
            context.push_str(&format!("- **File Path**: `{}`\n", filepath));
            
            // Extract directory information
            if let Some(parent) = Path::new(filepath).parent() {
                context.push_str(&format!("- **Directory**: `{}`\n", parent.display()));
                
                // Analyze directory depth and structure
                let depth = Path::new(filepath).components().count();
                context.push_str(&format!("- **Directory Depth**: {} levels\n", depth));
                
                // Extract directory components for context
                let components: Vec<_> = Path::new(filepath)
                    .components()
                    .filter_map(|c| c.as_os_str().to_str())
                    .collect();
                
                if components.len() > 1 {
                    context.push_str("- **Path Components**: ");
                    for (i, component) in components.iter().enumerate() {
                        if i > 0 { context.push_str(" â†’ "); }
                        context.push_str(&format!("`{}`", component));
                    }
                    context.push_str("\n");
                }
            }
        }

        if let Some(filename) = &metadata.filename {
            context.push_str(&format!("- **Filename**: `{}`\n", filename));
            
            // Analyze filename patterns
            let filename_analysis = self.analyze_filename_patterns(filename);
            if !filename_analysis.is_empty() {
                context.push_str(&format!("- **Filename Patterns**: {}\n", filename_analysis.join(", ")));
            }
        }

        if let Some(extension) = &metadata.extension {
            context.push_str(&format!("- **Extension**: `{}`\n", extension));
        }

        if let Some(file_type) = &metadata.file_type {
            context.push_str(&format!("- **File Type**: `{}`\n", file_type));
        }

        if let Some(line_count) = metadata.line_count {
            context.push_str(&format!("- **Line Count**: {}\n", line_count));
        }

        if let Some(word_count) = metadata.word_count {
            context.push_str(&format!("- **Word Count**: {}\n", word_count));
        }

        if let Some(file_size) = metadata.file_size_bytes {
            context.push_str(&format!("- **File Size**: {} bytes\n", file_size));
        }

        context.push_str("\n## Import/Include Analysis\n\n");

        // Analyze imports/includes based on file extension
        let imports = self.extract_imports(content, metadata.extension.as_deref());
        if imports.is_empty() {
            context.push_str("- No imports/includes detected\n");
        } else {
            context.push_str(&format!("### Detected {} import(s)/include(s):\n\n", imports.len()));
            
            // Categorize imports
            let categorized_imports = self.categorize_imports(&imports, metadata.extension.as_deref());
            
            for (category, category_imports) in categorized_imports {
                if !category_imports.is_empty() {
                    context.push_str(&format!("**{}:**\n", category));
                    for import in category_imports {
                        context.push_str(&format!("- `{}`\n", import));
                    }
                    context.push_str("\n");
                }
            }
        }

        context.push_str("## Module-Level Dependencies\n\n");
        
        // Analyze module-level dependencies
        let module_deps = self.analyze_module_dependencies(content, metadata);
        if module_deps.is_empty() {
            context.push_str("- No module-level dependencies detected\n");
        } else {
            for dep in module_deps {
                context.push_str(&format!("- {}\n", dep));
            }
        }

        context.push_str("\n## Directory Structure Context\n\n");
        
        // Provide directory context based on path analysis
        if let Some(filepath) = &metadata.filepath {
            let dir_context = self.analyze_directory_context(filepath);
            if dir_context.is_empty() {
                context.push_str("- Standard file location\n");
            } else {
                for ctx in dir_context {
                    context.push_str(&format!("- {}\n", ctx));
                }
            }
        }
        
        context.push_str("\n*Note: Full directory structure analysis would require access to the complete repository.*\n");
        context.push_str("*This context focuses on the immediate file and its detected dependencies.*\n\n");

        // Add raw content at the end
        context.push_str("## Original File Content\n\n");
        context.push_str("```\n");
        context.push_str(content);
        context.push_str("\n```\n");

        context
    }

    /// Generate L2 context (architectural context)
    ///
    /// L2 context includes:
    /// - Package/crate structure
    /// - Cross-module relationships
    /// - Architectural patterns and constraints
    ///
    /// # Arguments
    /// * `content` - Raw file content
    /// * `metadata` - File metadata from database
    ///
    /// # Returns
    /// * `String` - Generated L2 context
    pub fn generate_l2_context(&self, content: &str, metadata: &RowMetadata) -> String {
        debug!("Generating L2 context for file: {:?}", metadata.filepath);

        let mut context = String::new();

        // Add architectural context header
        context.push_str("# L2 Context: Architectural Context\n\n");
        context.push_str("## Package/Module Structure\n\n");

        if let Some(filepath) = &metadata.filepath {
            // Analyze package/module structure from path
            let path_components: Vec<&str> = Path::new(filepath)
                .components()
                .filter_map(|c| c.as_os_str().to_str())
                .collect();

            context.push_str(&format!("- **Path Depth**: {} levels\n", path_components.len()));
            context.push_str("- **Path Components**:\n");
            for (i, component) in path_components.iter().enumerate() {
                context.push_str(&format!("  {}. `{}`\n", i + 1, component));
            }
        }

        context.push_str("\n## Architectural Patterns\n\n");

        // Detect architectural patterns based on content and path
        let patterns = self.detect_architectural_patterns(content, metadata);
        if patterns.is_empty() {
            context.push_str("- No specific architectural patterns detected\n");
        } else {
            for pattern in patterns {
                context.push_str(&format!("- {}\n", pattern));
            }
        }

        context.push_str("\n## Cross-Module Relationships\n\n");

        // Analyze potential cross-module relationships
        let relationships = self.analyze_cross_module_relationships(content, metadata);
        if relationships.is_empty() {
            context.push_str("- No cross-module relationships detected\n");
        } else {
            for relationship in relationships {
                context.push_str(&format!("- {}\n", relationship));
            }
        }

        context.push_str("\n## Technology Stack Analysis\n\n");

        // Analyze technology stack based on file extension and content
        let tech_stack = self.analyze_technology_stack(content, metadata);
        for tech in tech_stack {
            context.push_str(&format!("- {}\n", tech));
        }

        context.push_str("\n## Architectural Constraints\n\n");
        context.push_str("*Note: Architectural constraint analysis would require access to:*\n");
        context.push_str("- Build configuration files (Cargo.toml, package.json, etc.)\n");
        context.push_str("- Documentation and README files\n");
        context.push_str("- Test files and examples\n");
        context.push_str("- CI/CD configuration\n\n");

        // Include L1 context reference
        context.push_str("## L1 Context Reference\n\n");
        context.push_str("*This L2 context builds upon the L1 immediate file context.*\n");
        context.push_str("*Refer to the L1 context file for detailed import analysis and file metadata.*\n\n");

        context
    }

    /// Extract imports/includes from content based on file type
    fn extract_imports(&self, content: &str, extension: Option<&str>) -> Vec<String> {
        let mut imports = Vec::new();

        match extension {
            Some("rs") => {
                // Rust imports
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("use ") && trimmed.ends_with(';') {
                        imports.push(trimmed.to_string());
                    } else if trimmed.starts_with("extern crate ") {
                        imports.push(trimmed.to_string());
                    } else if trimmed.starts_with("mod ") && trimmed.ends_with(';') {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            Some("py") => {
                // Python imports
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("import ") || trimmed.starts_with("from ") {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            Some("js") | Some("ts") => {
                // JavaScript/TypeScript imports
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("import ") || 
                       (trimmed.starts_with("const ") && trimmed.contains("require(")) ||
                       (trimmed.starts_with("let ") && trimmed.contains("require(")) ||
                       (trimmed.starts_with("var ") && trimmed.contains("require(")) {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            Some("c") | Some("cpp") | Some("h") | Some("hpp") => {
                // C/C++ includes
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("#include ") {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            Some("go") => {
                // Go imports
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("import ") {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            Some("java") => {
                // Java imports
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("import ") && trimmed.ends_with(';') {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            _ => {
                // Generic pattern matching for other languages
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.contains("import") || trimmed.contains("include") || trimmed.contains("require") {
                        imports.push(trimmed.to_string());
                    }
                }
            }
        }

        imports
    }

    /// Analyze filename patterns to extract semantic information
    fn analyze_filename_patterns(&self, filename: &str) -> Vec<String> {
        let mut patterns = Vec::new();
        let filename_lower = filename.to_lowercase();

        // Common filename patterns
        if filename_lower.contains("test") || filename_lower.contains("spec") {
            patterns.push("Test file".to_string());
        }
        if filename_lower.contains("main") {
            patterns.push("Main/entry point file".to_string());
        }
        if filename_lower.contains("lib") {
            patterns.push("Library file".to_string());
        }
        if filename_lower.contains("mod") {
            patterns.push("Module file".to_string());
        }
        if filename_lower.contains("config") || filename_lower.contains("settings") {
            patterns.push("Configuration file".to_string());
        }
        if filename_lower.contains("util") || filename_lower.contains("helper") {
            patterns.push("Utility file".to_string());
        }
        if filename_lower.contains("error") {
            patterns.push("Error handling file".to_string());
        }
        if filename_lower.contains("cli") || filename_lower.contains("cmd") {
            patterns.push("Command-line interface file".to_string());
        }
        if filename_lower.contains("api") {
            patterns.push("API file".to_string());
        }
        if filename_lower.contains("db") || filename_lower.contains("database") {
            patterns.push("Database-related file".to_string());
        }

        patterns
    }

    /// Categorize imports by type (standard library, external, internal, etc.)
    fn categorize_imports(&self, imports: &[String], extension: Option<&str>) -> Vec<(String, Vec<String>)> {
        let mut categories: std::collections::HashMap<String, Vec<String>> = std::collections::HashMap::new();

        for import in imports {
            let category = match extension {
                Some("rs") => {
                    if import.contains("std::") {
                        "Standard Library"
                    } else if import.contains("crate::") {
                        "Internal Crate"
                    } else if import.starts_with("use ") && !import.contains("::") {
                        "External Crate"
                    } else if import.starts_with("extern crate") {
                        "External Crate"
                    } else if import.starts_with("mod ") {
                        "Module Declaration"
                    } else {
                        "External Crate"
                    }
                }
                Some("py") => {
                    if import.starts_with("from .") || import.starts_with("import .") {
                        "Relative Import"
                    } else if import.contains("from ") && !import.contains(".") {
                        "Standard/External Library"
                    } else {
                        "Standard/External Library"
                    }
                }
                Some("js") | Some("ts") => {
                    if import.contains("./") || import.contains("../") {
                        "Relative Import"
                    } else if import.contains("node_modules") || !import.contains("/") {
                        "External Package"
                    } else {
                        "Internal Module"
                    }
                }
                Some("c") | Some("cpp") | Some("h") | Some("hpp") => {
                    if import.contains("<") && import.contains(">") {
                        "System Header"
                    } else if import.contains("\"") {
                        "Local Header"
                    } else {
                        "Header File"
                    }
                }
                _ => "Import/Include"
            };

            categories.entry(category.to_string()).or_default().push(import.clone());
        }

        categories.into_iter().collect()
    }

    /// Analyze module-level dependencies from content
    fn analyze_module_dependencies(&self, content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut dependencies = Vec::new();

        // Look for function calls that indicate dependencies
        if content.contains("::") {
            dependencies.push("Uses qualified path syntax (indicates module relationships)".to_string());
        }

        // Language-specific dependency analysis
        match metadata.extension.as_deref() {
            Some("rs") => {
                if content.contains("pub mod ") {
                    dependencies.push("Declares public modules".to_string());
                }
                if content.contains("pub use ") {
                    dependencies.push("Re-exports items from other modules".to_string());
                }
                if content.contains("impl ") {
                    dependencies.push("Implements traits or methods".to_string());
                }
                if content.contains("derive(") {
                    dependencies.push("Uses derive macros".to_string());
                }
            }
            Some("py") => {
                if content.contains("class ") {
                    dependencies.push("Defines classes".to_string());
                }
                if content.contains("def ") {
                    dependencies.push("Defines functions".to_string());
                }
                if content.contains("@") {
                    dependencies.push("Uses decorators".to_string());
                }
            }
            Some("js") | Some("ts") => {
                if content.contains("export ") {
                    dependencies.push("Exports modules/functions".to_string());
                }
                if content.contains("class ") {
                    dependencies.push("Defines classes".to_string());
                }
                if content.contains("function ") {
                    dependencies.push("Defines functions".to_string());
                }
            }
            _ => {}
        }

        dependencies
    }

    /// Analyze directory context from file path
    fn analyze_directory_context(&self, filepath: &str) -> Vec<String> {
        let mut context = Vec::new();
        let path_lower = filepath.to_lowercase();

        // Common directory patterns
        if path_lower.contains("/src/") || path_lower.starts_with("src/") {
            context.push("Located in source code directory".to_string());
        }
        if path_lower.contains("/lib/") || path_lower.contains("/libs/") {
            context.push("Located in library directory".to_string());
        }
        if path_lower.contains("/test/") || path_lower.contains("/tests/") {
            context.push("Located in test directory".to_string());
        }
        if path_lower.contains("/bin/") || path_lower.contains("/bins/") {
            context.push("Located in binary/executable directory".to_string());
        }
        if path_lower.contains("/examples/") || path_lower.contains("/example/") {
            context.push("Located in examples directory".to_string());
        }
        if path_lower.contains("/docs/") || path_lower.contains("/doc/") {
            context.push("Located in documentation directory".to_string());
        }
        if path_lower.contains("/config/") || path_lower.contains("/configs/") {
            context.push("Located in configuration directory".to_string());
        }
        if path_lower.contains("/utils/") || path_lower.contains("/util/") {
            context.push("Located in utilities directory".to_string());
        }
        if path_lower.contains("/api/") {
            context.push("Located in API directory".to_string());
        }
        if path_lower.contains("/cli/") {
            context.push("Located in CLI directory".to_string());
        }
        if path_lower.contains("/database/") || path_lower.contains("/db/") {
            context.push("Located in database directory".to_string());
        }

        // Analyze nesting level
        let depth = filepath.matches('/').count();
        if depth > 3 {
            context.push(format!("Deeply nested file ({} levels deep)", depth));
        } else if depth == 0 {
            context.push("Root-level file".to_string());
        }

        context
    }

    /// Detect architectural patterns from content and metadata
    fn detect_architectural_patterns(&self, content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut patterns = Vec::new();

        // Pattern detection based on file path
        if let Some(filepath) = &metadata.filepath {
            let path_lower = filepath.to_lowercase();
            
            if path_lower.contains("/src/") {
                patterns.push("Source code organization pattern".to_string());
            }
            if path_lower.contains("/lib/") || path_lower.contains("/libs/") {
                patterns.push("Library organization pattern".to_string());
            }
            if path_lower.contains("/test/") || path_lower.contains("/tests/") {
                patterns.push("Test organization pattern".to_string());
            }
            if path_lower.contains("/bin/") {
                patterns.push("Binary/executable pattern".to_string());
            }
            if path_lower.contains("/mod.rs") || path_lower.contains("/lib.rs") || path_lower.contains("/main.rs") {
                patterns.push("Rust module system pattern".to_string());
            }
        }

        // Pattern detection based on content
        let content_lower = content.to_lowercase();
        
        if content_lower.contains("struct") && content_lower.contains("impl") {
            patterns.push("Object-oriented design pattern".to_string());
        }
        if content_lower.contains("trait") {
            patterns.push("Trait-based design pattern".to_string());
        }
        if content_lower.contains("async") || content_lower.contains("await") {
            patterns.push("Asynchronous programming pattern".to_string());
        }
        if content_lower.contains("macro_rules!") || content_lower.contains("#[derive") {
            patterns.push("Macro-based code generation pattern".to_string());
        }
        if content_lower.contains("error") && content_lower.contains("result") {
            patterns.push("Error handling pattern".to_string());
        }

        patterns
    }

    /// Analyze cross-module relationships
    fn analyze_cross_module_relationships(&self, content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut relationships = Vec::new();

        // Analyze based on imports and usage patterns
        let imports = self.extract_imports(content, metadata.extension.as_deref());
        
        for import in imports {
            if import.contains("::") {
                relationships.push(format!("Module dependency: {}", import));
            } else if import.contains("crate::") {
                relationships.push(format!("Internal crate dependency: {}", import));
            } else if import.contains("std::") {
                relationships.push(format!("Standard library dependency: {}", import));
            } else {
                relationships.push(format!("External dependency: {}", import));
            }
        }

        // Analyze function calls and type usage
        if content.contains("::") {
            relationships.push("Uses qualified path syntax (indicates module relationships)".to_string());
        }

        relationships
    }

    /// Analyze technology stack from content and metadata
    fn analyze_technology_stack(&self, content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut tech_stack = Vec::new();

        // Language detection
        if let Some(extension) = &metadata.extension {
            match extension.as_str() {
                "rs" => tech_stack.push("Language: Rust".to_string()),
                "py" => tech_stack.push("Language: Python".to_string()),
                "js" => tech_stack.push("Language: JavaScript".to_string()),
                "ts" => tech_stack.push("Language: TypeScript".to_string()),
                "c" => tech_stack.push("Language: C".to_string()),
                "cpp" | "cc" | "cxx" => tech_stack.push("Language: C++".to_string()),
                "java" => tech_stack.push("Language: Java".to_string()),
                "go" => tech_stack.push("Language: Go".to_string()),
                _ => tech_stack.push(format!("Language: {} (detected from extension)", extension)),
            }
        }

        // Framework/library detection based on content
        let content_lower = content.to_lowercase();
        
        if content_lower.contains("tokio") {
            tech_stack.push("Framework: Tokio (async runtime)".to_string());
        }
        if content_lower.contains("serde") {
            tech_stack.push("Library: Serde (serialization)".to_string());
        }
        if content_lower.contains("sqlx") {
            tech_stack.push("Library: SQLx (database)".to_string());
        }
        if content_lower.contains("axum") || content_lower.contains("warp") || content_lower.contains("actix") {
            tech_stack.push("Framework: Web framework detected".to_string());
        }
        if content_lower.contains("clap") {
            tech_stack.push("Library: Clap (CLI)".to_string());
        }

        tech_stack
    }

    /// Write content to a file
    async fn write_content_file(&self, file_path: &Path, content: &str) -> TaskResult<()> {
        tokio::fs::write(file_path, content).await.map_err(|e| {
            TaskError::TaskFileCreationFailed {
                path: file_path.display().to_string(),
                cause: format!("Failed to write content file: {}", e),
            }
        })?;

        debug!("Wrote content file: {}", file_path.display());
        Ok(())
    }

    /// Extract metadata from a database row
    fn extract_row_metadata(&self, row: &sqlx::postgres::PgRow) -> TaskResult<RowMetadata> {
        Ok(RowMetadata {
            file_id: row.try_get("file_id").ok(),
            filepath: row.try_get("filepath").ok(),
            filename: row.try_get("filename").ok(),
            extension: row.try_get("extension").ok(),
            file_size_bytes: row.try_get("file_size_bytes").ok(),
            line_count: row.try_get("line_count").ok(),
            word_count: row.try_get("word_count").ok(),
            content_text: row.try_get("content_text").ok(),
            file_type: row.try_get("file_type").ok(),
            relative_path: row.try_get("relative_path").ok(),
            absolute_path: row.try_get("absolute_path").ok(),
        })
    }

    /// Validate table name to prevent SQL injection
    fn validate_table_name(&self, table_name: &str) -> TaskResult<()> {
        if table_name.is_empty() {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: "Table name cannot be empty".to_string(),
            });
        }

        // Check for basic SQL injection patterns
        let invalid_chars = ['\'', '"', ';', '\\'];
        let invalid_strings = ["--", "/*", "*/"];
        if table_name.chars().any(|c| invalid_chars.contains(&c)) || 
           invalid_strings.iter().any(|s| table_name.contains(s)) {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' contains invalid characters", table_name),
            });
        }

        // Check length (PostgreSQL identifier limit is 63 characters)
        if table_name.len() > 63 {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' exceeds maximum length of 63 characters", table_name),
            });
        }

        // Check that it starts with a letter or underscore
        if !table_name.chars().next().unwrap().is_ascii_alphabetic() && !table_name.starts_with('_') {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' must start with a letter or underscore", table_name),
            });
        }

        // Check that it only contains valid characters (letters, digits, underscores)
        if !table_name.chars().all(|c| c.is_ascii_alphanumeric() || c == '_') {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' can only contain letters, digits, and underscores", table_name),
            });
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_metadata() -> RowMetadata {
        RowMetadata {
            file_id: Some(1),
            filepath: Some("src/lib.rs".to_string()),
            filename: Some("lib.rs".to_string()),
            extension: Some("rs".to_string()),
            file_size_bytes: Some(1024),
            line_count: Some(50),
            word_count: Some(200),
            content_text: Some("use std::collections::HashMap;\npub mod test;".to_string()),
            file_type: Some("direct_text".to_string()),
            relative_path: Some("src/lib.rs".to_string()),
            absolute_path: Some("/project/src/lib.rs".to_string()),
        }
    }

    #[test]
    fn test_extract_imports_rust() {
        let rust_content = r#"
use std::collections::HashMap;
use serde::{Serialize, Deserialize};
extern crate tokio;
// This is a comment
fn main() {}
"#;

        // Test the extract_imports method directly without creating ContentExtractor
        let imports = extract_imports_for_test(rust_content, Some("rs"));
        assert_eq!(imports.len(), 3);
        assert!(imports.contains(&"use std::collections::HashMap;".to_string()));
        assert!(imports.contains(&"use serde::{Serialize, Deserialize};".to_string()));
        assert!(imports.contains(&"extern crate tokio;".to_string()));
    }

    #[test]
    fn test_extract_imports_python() {
        let python_content = r#"
import os
import sys
from typing import Dict, List
from collections import defaultdict
# This is a comment
def main():
    pass
"#;

        let imports = extract_imports_for_test(python_content, Some("py"));
        assert_eq!(imports.len(), 4);
        assert!(imports.contains(&"import os".to_string()));
        assert!(imports.contains(&"import sys".to_string()));
        assert!(imports.contains(&"from typing import Dict, List".to_string()));
        assert!(imports.contains(&"from collections import defaultdict".to_string()));
    }

    #[test]
    fn test_generate_l1_context() {
        let metadata = create_test_metadata();
        let content = "use std::collections::HashMap;\npub mod test;";
        
        let l1_context = generate_l1_context_for_test(content, &metadata);
        
        assert!(l1_context.contains("# L1 Context: Immediate File Context"));
        assert!(l1_context.contains("src/lib.rs"));
        assert!(l1_context.contains("lib.rs"));
        assert!(l1_context.contains("rs"));
        assert!(l1_context.contains("50")); // line count
        assert!(l1_context.contains("200")); // word count
        assert!(l1_context.contains("use std::collections::HashMap;"));
        assert!(l1_context.contains("## Original File Content"));
        assert!(l1_context.contains("## Directory Structure Context"));
        assert!(l1_context.contains("## Module-Level Dependencies"));
    }

    #[test]
    fn test_l1_context_directory_analysis() {
        let mut metadata = create_test_metadata();
        metadata.filepath = Some("src/database/models.rs".to_string());
        metadata.filename = Some("models.rs".to_string());
        
        let content = "use sqlx::FromRow;\nuse serde::{Serialize, Deserialize};";
        let l1_context = generate_l1_context_for_test(content, &metadata);
        
        assert!(l1_context.contains("src/database/models.rs"));
        assert!(l1_context.contains("**Directory**: `src/database`"));
        assert!(l1_context.contains("Located in source code directory"));
    }

    #[test]
    fn test_l1_context_import_categorization() {
        let metadata = create_test_metadata();
        let content = r#"
use std::collections::HashMap;
use crate::internal::module;
use external_crate::SomeType;
use serde::{Serialize, Deserialize};
extern crate tokio;
mod local_module;
"#;
        
        let l1_context = generate_l1_context_for_test(content, &metadata);
        
        // Should detect all imports
        assert!(l1_context.contains("use std::collections::HashMap;"));
        assert!(l1_context.contains("use crate::internal::module;"));
        assert!(l1_context.contains("use external_crate::SomeType;"));
        assert!(l1_context.contains("use serde::{Serialize, Deserialize};"));
        assert!(l1_context.contains("extern crate tokio;"));
        assert!(l1_context.contains("mod local_module;"));
    }

    #[test]
    fn test_l1_context_module_dependencies() {
        let metadata = create_test_metadata();
        let content = r#"
use std::collections::HashMap;

fn test_function() {
    let map = HashMap::new();
    crate::other::function();
}
"#;
        
        let l1_context = generate_l1_context_for_test(content, &metadata);
        
        assert!(l1_context.contains("Uses qualified path syntax"));
    }

    #[test]
    fn test_generate_l2_context() {
        let metadata = create_test_metadata();
        let content = "use std::collections::HashMap;\npub mod test;\nstruct MyStruct {}";
        
        let l2_context = generate_l2_context_for_test(content, &metadata);
        
        assert!(l2_context.contains("# L2 Context: Architectural Context"));
        assert!(l2_context.contains("## Package/Module Structure"));
        assert!(l2_context.contains("## Architectural Patterns"));
        assert!(l2_context.contains("## Cross-Module Relationships"));
        assert!(l2_context.contains("## Technology Stack Analysis"));
        assert!(l2_context.contains("Language: Rust"));
    }

    #[test]
    fn test_detect_architectural_patterns() {
        let mut metadata = create_test_metadata();
        metadata.filepath = Some("src/lib.rs".to_string());
        
        let content = r#"
struct MyStruct {
    field: String,
}

impl MyStruct {
    async fn new() -> Self {
        Self { field: String::new() }
    }
}

trait MyTrait {
    fn method(&self);
}
"#;
        
        let patterns = detect_architectural_patterns_for_test(content, &metadata);
        
        // Check that we detect the patterns we expect
        assert!(patterns.iter().any(|p| p.contains("Source code organization")));
        assert!(patterns.iter().any(|p| p.contains("Object-oriented design")));
        assert!(patterns.iter().any(|p| p.contains("Trait-based design")));
        assert!(patterns.iter().any(|p| p.contains("Asynchronous programming")));
        
        // Verify we have at least some patterns
        assert!(!patterns.is_empty(), "Should detect some architectural patterns");
    }

    #[test]
    fn test_analyze_cross_module_relationships() {
        let metadata = create_test_metadata();
        let content = r#"
use std::collections::HashMap;
use crate::internal::module;
use external_crate::SomeType;
use self::local_module;

fn test() {
    let x = module::function();
}
"#;
        
        let relationships = analyze_cross_module_relationships_for_test(content, &metadata);
        
        assert!(relationships.iter().any(|r| r.contains("Standard library dependency")));
        assert!(relationships.iter().any(|r| r.contains("Internal crate dependency")));
        assert!(relationships.iter().any(|r| r.contains("External dependency")));
        assert!(relationships.iter().any(|r| r.contains("qualified path syntax")));
    }

    #[test]
    fn test_analyze_technology_stack() {
        let metadata = create_test_metadata();
        let content = r#"
use tokio::runtime::Runtime;
use serde::{Serialize, Deserialize};
use sqlx::PgPool;
use axum::Router;
use clap::Parser;
"#;
        
        let tech_stack = analyze_technology_stack_for_test(content, &metadata);
        
        assert!(tech_stack.iter().any(|t| t.contains("Language: Rust")));
        assert!(tech_stack.iter().any(|t| t.contains("Tokio")));
        assert!(tech_stack.iter().any(|t| t.contains("Serde")));
        assert!(tech_stack.iter().any(|t| t.contains("SQLx")));
        assert!(tech_stack.iter().any(|t| t.contains("Web framework")));
        assert!(tech_stack.iter().any(|t| t.contains("Clap")));
    }

    #[test]
    fn test_l2_context_completeness() {
        let mut metadata = create_test_metadata();
        metadata.filepath = Some("src/database/models/user.rs".to_string());
        metadata.filename = Some("user.rs".to_string());
        
        let content = r#"
use std::collections::HashMap;
use serde::{Serialize, Deserialize};
use sqlx::FromRow;
use tokio::sync::RwLock;
use crate::database::connection::Database;
use crate::error::{UserError, UserResult};

#[derive(Debug, Clone, Serialize, Deserialize, FromRow)]
pub struct User {
    pub id: i64,
    pub username: String,
    pub email: String,
}

impl User {
    pub async fn create(db: &Database, username: String, email: String) -> UserResult<Self> {
        // Implementation here
        todo!()
    }
}

pub trait UserRepository {
    async fn find_by_id(&self, id: i64) -> UserResult<Option<User>>;
    async fn create(&self, user: User) -> UserResult<User>;
}
"#;
        
        let l2_context = generate_l2_context_for_test(content, &metadata);
        
        // Verify all required sections are present
        assert!(l2_context.contains("# L2 Context: Architectural Context"));
        assert!(l2_context.contains("## Package/Module Structure"));
        assert!(l2_context.contains("## Architectural Patterns"));
        assert!(l2_context.contains("## Cross-Module Relationships"));
        assert!(l2_context.contains("## Technology Stack Analysis"));
        
        // Verify path analysis
        assert!(l2_context.contains("**Path Depth**: 4 levels"));
        assert!(l2_context.contains("src"));
        assert!(l2_context.contains("database"));
        assert!(l2_context.contains("models"));
        assert!(l2_context.contains("user.rs"));
        
        // Verify technology stack detection
        assert!(l2_context.contains("Language: Rust"));
        
        println!("L2 Context:\n{}", l2_context);
    }

    #[test]
    fn test_validate_table_name() {
        // Valid table names
        assert!(validate_table_name_for_test("INGEST_20250928101039").is_ok());
        assert!(validate_table_name_for_test("valid_table").is_ok());
        assert!(validate_table_name_for_test("_private_table").is_ok());
        assert!(validate_table_name_for_test("Table123").is_ok());

        // Invalid table names
        assert!(validate_table_name_for_test("").is_err());
        assert!(validate_table_name_for_test("table'name").is_err());
        assert!(validate_table_name_for_test("table\"name").is_err());
        assert!(validate_table_name_for_test("table;name").is_err());
        assert!(validate_table_name_for_test("table--name").is_err());
        assert!(validate_table_name_for_test("123table").is_err());
        assert!(validate_table_name_for_test(&"a".repeat(64)).is_err()); // Too long
    }

    #[test]
    fn test_content_triple_structure() {
        let content_triple = ContentTriple {
            content_a: PathBuf::from("/tmp/test_1_Content.txt"),
            content_b: PathBuf::from("/tmp/test_1_Content_L1.txt"),
            content_c: PathBuf::from("/tmp/test_1_Content_L2.txt"),
            row_number: 1,
            table_name: "INGEST_test".to_string(),
        };

        assert_eq!(content_triple.row_number, 1);
        assert_eq!(content_triple.table_name, "INGEST_test");
        assert!(content_triple.content_a.to_string_lossy().contains("Content.txt"));
        assert!(content_triple.content_b.to_string_lossy().contains("Content_L1.txt"));
        assert!(content_triple.content_c.to_string_lossy().contains("Content_L2.txt"));
    }

    // Helper functions for testing without database connections
    fn extract_imports_for_test(content: &str, extension: Option<&str>) -> Vec<String> {
        let mut imports = Vec::new();

        match extension {
            Some("rs") => {
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("use ") && trimmed.ends_with(';') {
                        imports.push(trimmed.to_string());
                    } else if trimmed.starts_with("extern crate ") {
                        imports.push(trimmed.to_string());
                    } else if trimmed.starts_with("mod ") && trimmed.ends_with(';') {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            Some("py") => {
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.starts_with("import ") || trimmed.starts_with("from ") {
                        imports.push(trimmed.to_string());
                    }
                }
            }
            _ => {}
        }

        imports
    }

    fn generate_l1_context_for_test(content: &str, metadata: &RowMetadata) -> String {
        let mut context = String::new();

        context.push_str("# L1 Context: Immediate File Context\n\n");
        context.push_str("## File Information\n\n");

        if let Some(filepath) = &metadata.filepath {
            context.push_str(&format!("- **File Path**: `{}`\n", filepath));
            
            if let Some(parent) = Path::new(filepath).parent() {
                context.push_str(&format!("- **Directory**: `{}`\n", parent.display()));
            }
        }

        if let Some(filename) = &metadata.filename {
            context.push_str(&format!("- **Filename**: `{}`\n", filename));
        }

        if let Some(extension) = &metadata.extension {
            context.push_str(&format!("- **Extension**: `{}`\n", extension));
        }

        if let Some(line_count) = metadata.line_count {
            context.push_str(&format!("- **Line Count**: {}\n", line_count));
        }

        if let Some(word_count) = metadata.word_count {
            context.push_str(&format!("- **Word Count**: {}\n", word_count));
        }

        context.push_str("\n## Import/Include Analysis\n\n");
        let imports = extract_imports_for_test(content, metadata.extension.as_deref());
        if imports.is_empty() {
            context.push_str("- No imports/includes detected\n");
        } else {
            for import in imports {
                context.push_str(&format!("- `{}`\n", import));
            }
        }

        context.push_str("\n## Module-Level Dependencies\n\n");
        if content.contains("::") {
            context.push_str("- Uses qualified path syntax (indicates module relationships)\n");
        } else {
            context.push_str("- No module-level dependencies detected\n");
        }

        context.push_str("\n## Directory Structure Context\n\n");
        if let Some(filepath) = &metadata.filepath {
            let path_lower = filepath.to_lowercase();
            if path_lower.contains("src/") {
                context.push_str("- Located in source code directory\n");
            } else {
                context.push_str("- Standard file location\n");
            }
        }

        context.push_str("\n## Original File Content\n\n");
        context.push_str("```\n");
        context.push_str(content);
        context.push_str("\n```\n");

        context
    }

    fn generate_l2_context_for_test(_content: &str, metadata: &RowMetadata) -> String {
        let mut context = String::new();

        // Add architectural context header
        context.push_str("# L2 Context: Architectural Context\n\n");
        context.push_str("## Package/Module Structure\n\n");

        if let Some(filepath) = &metadata.filepath {
            // Analyze package/module structure from path
            let path_components: Vec<&str> = std::path::Path::new(filepath)
                .components()
                .filter_map(|c| c.as_os_str().to_str())
                .collect();

            context.push_str(&format!("- **Path Depth**: {} levels\n", path_components.len()));
            context.push_str("- **Path Components**:\n");
            for (i, component) in path_components.iter().enumerate() {
                context.push_str(&format!("  {}. `{}`\n", i + 1, component));
            }
        }

        context.push_str("\n## Architectural Patterns\n\n");
        context.push_str("## Cross-Module Relationships\n\n");
        context.push_str("## Technology Stack Analysis\n\n");

        if let Some(extension) = &metadata.extension {
            match extension.as_str() {
                "rs" => context.push_str("- Language: Rust\n"),
                "py" => context.push_str("- Language: Python\n"),
                _ => context.push_str(&format!("- Language: {} (detected from extension)\n", extension)),
            }
        }

        context
    }

    fn detect_architectural_patterns_for_test(content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut patterns = Vec::new();

        if let Some(filepath) = &metadata.filepath {
            let path_lower = filepath.to_lowercase();
            if path_lower.contains("src/") {  // Changed from "/src/" to "src/"
                patterns.push("Source code organization pattern".to_string());
            }
        }

        let content_lower = content.to_lowercase();
        if content_lower.contains("struct") && content_lower.contains("impl") {
            patterns.push("Object-oriented design pattern".to_string());
        }
        if content_lower.contains("trait") {
            patterns.push("Trait-based design pattern".to_string());
        }
        if content_lower.contains("async") || content_lower.contains("await") {
            patterns.push("Asynchronous programming pattern".to_string());
        }

        patterns
    }

    fn analyze_cross_module_relationships_for_test(content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut relationships = Vec::new();

        let imports = extract_imports_for_test(content, metadata.extension.as_deref());
        
        for import in imports {
            if import.contains("std::") {
                relationships.push(format!("Standard library dependency: {}", import));
            } else if import.contains("crate::") {
                relationships.push(format!("Internal crate dependency: {}", import));
            } else {
                relationships.push(format!("External dependency: {}", import));
            }
        }

        if content.contains("::") {
            relationships.push("Uses qualified path syntax (indicates module relationships)".to_string());
        }

        relationships
    }

    fn analyze_technology_stack_for_test(content: &str, metadata: &RowMetadata) -> Vec<String> {
        let mut tech_stack = Vec::new();

        if let Some(extension) = &metadata.extension {
            match extension.as_str() {
                "rs" => tech_stack.push("Language: Rust".to_string()),
                "py" => tech_stack.push("Language: Python".to_string()),
                _ => tech_stack.push(format!("Language: {} (detected from extension)", extension)),
            }
        }

        let content_lower = content.to_lowercase();
        if content_lower.contains("tokio") {
            tech_stack.push("Framework: Tokio (async runtime)".to_string());
        }
        if content_lower.contains("serde") {
            tech_stack.push("Library: Serde (serialization)".to_string());
        }
        if content_lower.contains("sqlx") {
            tech_stack.push("Library: SQLx (database)".to_string());
        }
        if content_lower.contains("axum") {
            tech_stack.push("Framework: Web framework detected".to_string());
        }
        if content_lower.contains("clap") {
            tech_stack.push("Library: Clap (CLI)".to_string());
        }

        tech_stack
    }

    fn validate_table_name_for_test(table_name: &str) -> TaskResult<()> {
        if table_name.is_empty() {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: "Table name cannot be empty".to_string(),
            });
        }

        let invalid_chars = ['\'', '"', ';', '\\'];
        let invalid_strings = ["--", "/*", "*/"];
        if table_name.chars().any(|c| invalid_chars.contains(&c)) || 
           invalid_strings.iter().any(|s| table_name.contains(s)) {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' contains invalid characters", table_name),
            });
        }

        if table_name.len() > 63 {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' exceeds maximum length of 63 characters", table_name),
            });
        }

        if !table_name.chars().next().unwrap().is_ascii_alphabetic() && !table_name.starts_with('_') {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' must start with a letter or underscore", table_name),
            });
        }

        if !table_name.chars().all(|c| c.is_ascii_alphanumeric() || c == '_') {
            return Err(TaskError::InvalidTaskConfiguration {
                cause: format!("Table name '{}' can only contain letters, digits, and underscores", table_name),
            });
        }

        Ok(())
    }
}